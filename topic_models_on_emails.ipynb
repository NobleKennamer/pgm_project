{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from curses.ascii import isprint\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(open('stop_words').read().split('\\n')[:-1])\n",
    "#stop_words = 'the,for,to,you,call,that'.split(',')\n",
    "#print stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove any beginning or ending whitespace\n",
    "    text.strip()\n",
    "    # Combine conjunctions\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    # Replace punctuation with space\n",
    "    text = text.translate(string.maketrans(string.punctuation,''.join(\" \" for char in string.punctuation)))\n",
    "    # Replace all control characters\n",
    "    #text = ''.join(char for char in text if isprint(char))\n",
    "    #text = re.sub(r\"\\n\", \" \", text)\n",
    "    # Remove Digits\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    \n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text_list = [token for token in text.split() if token not in stop_words and len(token) > 1]\n",
    "    \n",
    "    return text_list\n",
    "\n",
    "def get_name_from_id(person_id):\n",
    "    return alias_table[alias_table[\"PersonId\"] == person_id][\"Alias\"].iloc[0]\n",
    "\n",
    "def get_receivers(email_id):\n",
    "    return list(email_rec_table[email_rec_table[\"EmailId\"] == email_id][\"PersonId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails_table = pd.read_csv(\"data/emails/Emails.csv\").dropna()\n",
    "person_table = pd.read_csv(\"data/emails/Persons.csv\").dropna()\n",
    "alias_table = pd.read_csv(\"data/emails/Aliases.csv\").dropna()\n",
    "email_rec_table = pd.read_csv(\"data/emails/EmailReceivers.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails_table['ReceiverId'] = emails_table[\"Id\"].apply(lambda email_id: get_receivers(email_id))\n",
    "emails_table['doc'] = emails_table[\"ExtractedSubject\"] + \" \" + emails_table[\"ExtractedBodyText\"]\n",
    "emails_table['token_list'] = emails_table['doc'].apply(lambda s: clean_text(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "personId_to_docs = defaultdict(list)\n",
    "doc_number = 0\n",
    "for index, row in emails_table.iterrows():\n",
    "    for p_id in row[\"ReceiverId\"]:\n",
    "        if p_id != 80:\n",
    "            personId_to_docs[str(p_id)].append(doc_number)\n",
    "    \n",
    "    sender_id = int(row[\"SenderPersonId\"])\n",
    "    if sender_id != 80:\n",
    "        personId_to_docs[str(sender_id)].append(doc_number)\n",
    "    \n",
    "    doc_number += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(list(emails_table['token_list']))\n",
    "dictionary.save('models/dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in emails_table['token_list']]\n",
    "gensim.corpora.MmCorpus.serialize('models/corpus.mm', corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=20)\n",
    "lda.save('models/emails_lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdp = gensim.models.hdpmodel.HdpModel(corpus, dictionary, T=50)                                  \n",
    "hdp.save('models/emails_hdp.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "personId_to_topic_prob = defaultdict(list)\n",
    "\n",
    "for person_id in personId_to_docs.keys():\n",
    "    for top_num in range(lda.num_topics):\n",
    "        personId_to_topic_prob[person_id].append(0.0)\n",
    "\n",
    "\n",
    "\n",
    "for person_id, doc_list in personId_to_docs.items():\n",
    "    name =  get_name_from_id(int(person_id))\n",
    "    num_docs_assignmed = float(len(doc_list))\n",
    "    for doc_num in doc_list:\n",
    "        topic_dist = lda[corpus[doc_num]]\n",
    "        for topic, probability in topic_dist:\n",
    "            personId_to_topic_prob[person_id][topic] += (probability / num_docs_assignmed) * 100.0\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bipartite_graph = dict()\n",
    "bipartite_graph[\"nodes\"] = []\n",
    "bipartite_graph[\"edges\"] = []\n",
    "\n",
    "target = 0\n",
    "for topic_num in range(lda.num_topics):\n",
    "    bipartite_graph[\"nodes\"].append({\"name\": str(topic_num), \"value\": 1})\n",
    "    target += 1\n",
    "\n",
    "\n",
    "for person_id, doc_list in personId_to_docs.items():\n",
    "    name =  get_name_from_id(int(person_id))\n",
    "    bipartite_graph[\"nodes\"].append({\"name\": name, \"value\": 0})\n",
    "    for topic, topic_prob in enumerate(personId_to_topic_prob[person_id]):\n",
    "        source = topic\n",
    "        if topic_prob > 0.0:\n",
    "            bipartite_graph[\"edges\"].append({\"source\": source, \"target\": target, \"weight\": topic_prob})    \n",
    "    target += 1\n",
    "\n",
    "\n",
    "with open('bipartite_graph/lda_data.json', 'w') as fp:\n",
    "    json.dump(bipartite_graph, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bipartite_graph = dict()\n",
    "bipartite_graph[\"nodes\"] = []\n",
    "bipartite_graph[\"edges\"] = []\n",
    "\n",
    "specific_person = 10\n",
    "\n",
    "target = 0\n",
    "for topic_num in range(lda.num_topics):\n",
    "    bipartite_graph[\"nodes\"].append({\"name\": str(topic_num), \"value\": 1})\n",
    "    target += 1\n",
    "\n",
    "\n",
    "for person_id, doc_list in personId_to_docs.items():\n",
    "    if int(person_id) == specific_person:\n",
    "        name =  get_name_from_id(int(person_id))\n",
    "        bipartite_graph[\"nodes\"].append({\"name\": name, \"value\": 0})\n",
    "        for topic, topic_prob in enumerate(personId_to_topic_prob[person_id]):\n",
    "            source = topic\n",
    "            if topic_prob > 0.0:\n",
    "                bipartite_graph[\"edges\"].append({\"source\": source, \"target\": target, \"weight\": topic_prob})    \n",
    "        target += 1\n",
    "\n",
    "\n",
    "with open('bipartite_graph/lda_specific_person.json', 'w') as fp:\n",
    "    json.dump(bipartite_graph, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
